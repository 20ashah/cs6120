+++
title = "Finding Redundant Structures in Data Flow Graphs"
[extra]
bio = """
  [Oliver][] is a CS PhD student in theory at Cornell, who does decision theory and category theory.

  [Alexa][] is a second-year student interested in the intersection of compilers and formal methods. She also enjoys feminist book clubs and cooking elaborate [fish truck][] meals.

  [Greg][] is a second-year student working on machine learning and digital humanities.

[alexa]: https://www.cs.cornell.edu/~avh
[greg]: https://www.cs.cornell.edu/~gyauney
[oliver]: https://www.cs.cornell.edu/~oli
[fish truck]: https://www.triphammermarketplace.com/events/
"""
latex = true

[[extra.authors]]
name = "Oliver Richardson"
link = "https://www.cs.cornell.edu/~oli"
[[extra.authors]]
name = "Alexa VanHattum"
link = "https://www.cs.cornell.edu/~avh"
[[extra.authors]]
name = "Gregory Yauney"
link = "https://www.cs.cornell.edu/~gyauney"
+++

In a conventional von Neumann architecture, we might think of computation at a
high level as as our computers faithfully carrying out a series of steps. Like
dominoes in a line, the program counter runs through each instruction once its
predecessor completes.


<img src="dominos.gif" width=60%/>


Of course, this mental model is far from the truthâ€”in modern out-of-order
processors, instructions are aggressively reordered to take advantage of
multiple processing elements at once. The major caveat here is that reordering
must respect the original program's _data flow_. That is, if an instruction
needs to use data that is generated by a previous instruction, then it cannot be
reordered to happen afterward. From this perspective, we can think of
computation as dictating the flow of data through operations. Each instruction
is a node, and dependencies form edges that flows along.

<img src="pipes.gif" width=50%/>


## Go with the flow


Fun introduction!

## Data flow graphs for computational acceleration

- Dependencies matter!
- DFGs nicely model spatial acceleration

## Building data flow graphs from LLVM

- Trade-offs:
- Machine instructions vs. IR instructions
- Static vs. dynamic DFGs
- Getting simple data flow "for free" vs. complexities of control flow

## Matching fixed DFG stencils

- Defining node matches
- Finding isomorphisms

## Generating common DFG stencils

- n-node vs. n-edge stencils
- Beam search
- Scaling

## Static and dynamic coverage

- Annotations on LLVM
- Embench benchmark suite
- Use fast stencils for slow/big applications

## Ongoing directions
- Extend to hyperblock/superblock
- Compare against dynamic DFGs
- Evaluate on accelerated hardware
- Find stencils for groups of applications
