+++
title = "Cost of Abstraction in Compilers for Accelerator Generation"
extra.author = "Rachit Nigam"
extra.bio = """
  [Rachit Nigam](https://rachitnigam.com) is a second year PhD student interested in
  programming languages & computer architecture. In his free time, he
  [subtweets](https://twitter.com/notypes/status/1170037148290080771) his advisor and [annoys tenured professors](https://twitter.com/natefoster/status/1074401015565291520).
"""
+++

The blog post provides and overview of the [FuTIL][] compiler infrastructure
for designing accelerator generators and compares the designs generated by
it with a hand-crafted compiler generator.

The results are **TODO**.

### Generating Hardware Accelerators

Hardware acceleration in the form of specialized processors has become
increasingly common---from the graphics processing units (GPUs) that
accelerate everything from shader programs to linear algebra, to the tens
of new specialized AI chips that promise to run your favorite machine learning
models an order of magnitude faster.

Field programmable gate arrays (FPGAs) are a kind of reconfigurable
architecture that can be used to simulate hardware designs.
More recently, they have been become widely available on public clouds such
as AWS and Azure, accelerating many kinds of computations.
For an in-depth look into reconfigurable fabrics for accelerator design,
see this [blog post][reconf-future].

While incredibly flexible, FPGAs are a pain to program. The tools and languages
repurpose preexisting hardware design languages such as Verilog and VHDL.
While perfectly usable for precise hardware design, Verilog-like languages
require specification of every gate, wire, and clock cycle.
Building and iterating accelerators with them is a chore; imagine trying to
implement a matrix-multiply kernel by specifying every single wire (then
try imagining changing one design parameter requiring a pervasive rewrite).

Because of this verbose and tedious programming model, researchers and
practitioners have tried to design higher level programming models, either
by re-purposing legacy languages like C/C++ or building [entirely][spatial]
[new][aetherling] [languages][dahlia].

However, building such languages requires a lot of infrastructure---designing
the frontend, picking an architectural template, optimizing the generated
hardware, and generating code that can be run on an FPGA.
Instead of redesigning everything from scratch, the [FuTIL][] infrastructure hopes
to create a "LLVM for hardware design" by allowing frontends to target a small,
but expressive language, and automatically handling the "boring" optimization
and generation problems.

### Fused Temporal Intermediate Language (FuTIL)

FuTIL is an intermediate language (IL) and a compiler infrastructure for building
accelerator generators.
This section provides a high-level overview for the IL.

Before understanding the role of FuTIL, we need to understand how modern
compilers are constructed.
Every major compiler uses an intermediate language to represent the input
programs, analyze them, and optimize them.
As compilers have grown in complexity, they have started using many different
ILs to represent different *abstraction levels*.
For example, the [Rust][] compiler uses three different IL to analyze and
optimize Rust programs: HIR for type checking the program, MIR to implement
Rust-specific optimizations, and LLVM IR to implement generic optimizations.
This IR-based organization structure allows Rust to reuse the optimizations in
the LLVM compiler toolchain while also implementing specific optimizations
using MIR.

FuTIL is a generic mid-level IR for accelerator generators. It sits in the
middle of the high-level input programs that imply an abstract architecture,
and the low-level Verilog programs that instantiate a concrete architecture.
By concretizing some aspects of the final architecture, while keeping others
abstract, FuTIL is able to implement optimizations that can be shared across
many different toolchains.

**FuTIL programs**. FuTIL programs are constructed using *components* which
roughly correspond to functions in the software world, and modules in the
hardware world.
Each component has three sections:
(1) *cells* which describes all hardware units used by the component,
(2) *wires* which describes connections between the hardware units, and
(3) *control* which describes the execution schedule of the program.
We elide the specifics of the first two sections. For a detailed overview,
please take a look at the [FuTIL paper][futil-paper].

The *control* program is the novel aspect of FuTIL's design. A control program
looks like:
```
seq {
  init;
  while lt.out with cmp {
    incr;
  }
}
```
Here, `seq` and `while` are two *control-flow operators*. They describe the
execution flow of the program. `init`, `incr`, and `cmp` are dataflow graphs
are defined in the *wires* section of the component. At a high-level, they
define an "action". For example, `init` might define the connections required
to initialize a register, `incr` for incrementing the value in the register,
and `cmp` defines the connections to compare the current value in the register.
Using these groups, the control program precisely describes the control flow.

The key insight in the design of FuTIL is that by explicitly representing
the control flow of a program, the mid-level IR can implement several
optimizations that would otherwise not be possible in a Verilog designs.
For example, if the control program says that two dataflow graphs execute
in sequence, we know that they can share the same hardware resource and that
they will never conflict.


### The Dahlia-to-FuTIL Compiler


### miniHLS: Statically Timed FSM Generation

### FuTIL vs miniHLS

[reconf-future]:
[futil]:
[spatial]:
[aetherling]:
[dahlia]:
[rust]:
[futil-paper]:
